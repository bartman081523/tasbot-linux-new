Things to do or try:

Evaluate each objective function by considering the magnitude of each
column's change times the weight of that column. Enable learnfun to
learn functions which don't satisfy the lexicographic ordering property.

Allow objective functions to consider both -byte and +byte. In the case
of column weights (above) use a domain of [-1.0, 1.0].

At search time, consider the magnitude of each evaluation, do statistical
analysis, etc. rather than simply counting increasing values.

Integrate over the values of intermediate steps when evaluating a plan.

Make a simple markov model of inputs instead of motif-based sequences.

Do some breadth-first search. When input doesn't affect next state, spend
less time searching and more time backtracking.

We should consider explicitly taking into account the tree of inputs,
since caching makes some kinds of exploration much cheaper than others.

Don't bother trying every next. Pick the best half, and some random
subset of the rest. Use the time instead to explore more futures.

When futures are bad in general, shorten them and have more of them.
When they are good, lengthen them and have fewer.

Can use number of successful (better) backtracks as a way of gauging how
globally good my state is.

Search by an iterated random process, where we look at all the first
steps, some of the second, fewer of the third, etc.

If we are stuck issuing a very low value move, jump back in time and
randomize.

Allow lex orderings that treat their bytes as signed?


games:
%  tetris!
%  karate kid!
  contra!
